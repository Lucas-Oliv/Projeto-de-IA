# -*- coding: utf-8 -*-
# ==============================================================================
# --- IMPORTS ---
# ==============================================================================
import requests
import pandas as pd
from bs4 import BeautifulSoup
import re
import os
import numpy as np
import matplotlib
matplotlib.use('Agg')
import matplotlib.pyplot as plt
import seaborn as sns
from datetime import datetime, timedelta

# Imports de Machine Learning
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.preprocessing import MinMaxScaler
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report
from imblearn.over_sampling import SMOTE

# ==============================================================================
# --- CONFIGURAÇÕES E FONTES DE DADOS ---
# ==============================================================================
FORCAR_ATUALIZACAO = False
FONTES_DE_DADOS = {
    # Usando uma lista menor para agilizar os testes, adicione mais se desejar
    "champions_2024": "https://www.vlr.gg/event/stats/2097/valorant-champions-2024",
    "masters_shanghai_2024": "https://www.vlr.gg/event/stats/1999/champions-tour-2024-masters-shanghai",
    "masters_madrid_2024": "https://www.vlr.gg/event/stats/1921/champions-tour-2024-masters-madrid",
    "champions_2023": "https://www.vlr.gg/event/stats/1657/valorant-champions-2023",
    "masters_tokyo_2023": "https://www.vlr.gg/event/stats/1494/champions-tour-2023-masters-tokyo",
}

# ==============================================================================
# --- FUNÇÕES DE COLETA E PROCESSAMENTO ---
# ==============================================================================

def get_vlr_stats_data(url, nome_campeonato):
    """Busca as estatísticas dos jogadores de uma URL de evento do VLR.gg."""
    print(f"-> Coletando dados de: {nome_campeonato}...")
    try:
        headers = {"User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/108.0.0.0 Safari/536"}
        response = requests.get(url, headers=headers)
        response.raise_for_status()
        soup = BeautifulSoup(response.content, 'lxml')
        stats_table = soup.find('table', class_='mod-stats')
        if not stats_table: return None
        
        table_headers = [th.get_text(strip=True) for th in stats_table.find('thead').find_all('th')]
        rows = []
        for tr in stats_table.find('tbody').find_all('tr'):
            cells = tr.find_all('td')
            if not cells: continue
            player_name_div = cells[0].find('div', class_='text-of')
            if not player_name_div: continue
            player_name = player_name_div.get_text(strip=True)
            team_name = cells[0].find('div', class_='stats-player-country').get_text(strip=True)
            # Ignorando a coluna de agentes para simplificar
            row_data = [player_name, team_name] + [cell.get_text(strip=True) for cell in cells[2:]]
            rows.append(row_data)
        
        df = pd.DataFrame(rows, columns=['Player', 'Team'] + table_headers[2:])
        df['Campeonato'] = nome_campeonato
        return df
    except Exception as e:
        print(f"ERRO ao processar a URL {url}: {e}")
        return None

def clean_and_convert_data(df):
    """Limpa e converte as colunas do DataFrame para os tipos corretos."""
    if df is None or df.empty: return None
    
    rename_map = {'Team': 'Equipa', 'Rnd': 'Rounds', 'K:D': 'KD', 'HS%': 'HS%'}
    df = df.rename(columns=rename_map)
    
    cols_to_process = ['Rounds', 'ACS', 'KD', 'ADR', 'KPR', 'APR', 'FKPR', 'FDPR', 'KAST', 'HS%']
    
    for col in cols_to_process:
        if col in df.columns:
            df[col] = df[col].astype(str).str.replace('%', '', regex=False)
            df[col] = pd.to_numeric(df[col], errors='coerce')
            
    return df

# ==============================================================================
# --- EXECUÇÃO PRINCIPAL (VERSÃO COM APLICAÇÃO PARALELA) ---
# ==============================================================================
if __name__ == "__main__":
    
    CACHE_FILE = "vlr_stats_cache.csv"
    df_completo = None

    # ETAPA 1: CARREGAR OU COLETAR OS DADOS
    if not FORCAR_ATUALIZACAO and os.path.exists(CACHE_FILE):
        print("--- Carregando dados do cache local ---")
        df_completo = pd.read_csv(CACHE_FILE)
    
    if df_completo is None:
        print("--- Cache inválido ou atualização forçada. Coletando dados da web... ---")
        todos_os_dados = []
        for nome_evento, url in FONTES_DE_DADOS.items():
            df_evento = get_vlr_stats_data(url, nome_evento) 
            if df_evento is not None: todos_os_dados.append(df_evento)
        
        if not todos_os_dados:
            print("\nERRO: Falha ao coletar dados.")
            exit()
        
        df_completo_raw = pd.concat(todos_os_dados, ignore_index=True)
        df_completo = clean_and_convert_data(df_completo_raw)
        df_completo.to_csv(CACHE_FILE, index=False)
        print(f"--- Dados salvos em cache no arquivo '{CACHE_FILE}' ---")

    # Inicia o bloco principal que conterá TODAS as análises
    try:
        ##########################################################################
        ###          PIPELINE DE MACHINE LEARNING (CLASSIFICAÇÃO)              ###
        ##########################################################################
        print("\n\n--- INICIANDO PIPELINE DE MACHINE LEARNING ---")

        # 1. PREPARAÇÃO DOS DADOS
        limite_acs_elite = 235.0
        df_completo['Tier'] = np.where(df_completo['ACS'] >= limite_acs_elite, 'Elite', 'Regular')
        features = ['Rounds', 'KD', 'ADR', 'KPR', 'APR', 'FKPR', 'FDPR', 'HS%', 'KAST']
        df_modelo = df_completo.dropna(subset=features + ['Tier']).copy()
        
        if df_modelo.empty or df_modelo['Tier'].nunique() < 2:
            raise ValueError("Dados insuficientes para treinar.")
            
        X = df_modelo[features]
        y = df_modelo['Tier']
        X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.3, random_state=123)
        
        scaler = MinMaxScaler()
        X_train_scaled = scaler.fit_transform(X_train)
        X_test_scaled = scaler.transform(X_test)

        # 2. BALANCEAMENTO COM SMOTE
        print("\n[ML] Aplicando SMOTE para balancear o conjunto de treino...")
        smote = SMOTE(random_state=123)
        X_train_balanced, y_train_balanced = smote.fit_resample(X_train_scaled, y_train)

        # 3. TREINAMENTO DOS DOIS MODELOS FINAIS
        print("\n[ML] Iniciando o treinamento dos modelos focados...")
        save_estimators_final = []
        base_estimators = [
            LogisticRegression(max_iter=1000), 
            RandomForestClassifier(random_state=123)
        ]
        param_grids = [
            {'C': [0.1, 1.0, 10]}, 
            {'n_estimators': [100, 200], 'max_depth': [5, 7, None]}
        ]

        for i in range(len(base_estimators)):
            model_name = type(base_estimators[i]).__name__
            print(f"--- Treinando {model_name}... ---")
            clf = GridSearchCV(base_estimators[i], param_grids[i], cv=5, scoring='accuracy', n_jobs=-1)
            clf.fit(X_train_balanced, y_train_balanced)
            save_estimators_final.append(clf.best_estimator_)
            print(f"--- {model_name} treinado. ---")

        # 4. AVALIAÇÃO INDIVIDUAL DOS MODELOS
        print("\n[ML] Avaliando modelos no conjunto de teste...")
        for model in save_estimators_final:
            print(f"\n--- Avaliação para: {type(model).__name__} ---")
            y_pred = model.predict(X_test_scaled)
            print(classification_report(y_test, y_pred))
            
        # 5. IDENTIFICAR E ARMAZENAR OS MODELOS FINAIS (SEM COMPARAÇÃO)
        modelos_finais = {}
        for model in save_estimators_final:
            if isinstance(model, RandomForestClassifier):
                modelos_finais['RandomForest'] = model
            elif isinstance(model, LogisticRegression):
                modelos_finais['Regressão Logística'] = model

        print(f"\n[ML] Modelos finalizados e prontos para uso: {list(modelos_finais.keys())}")


        ##########################################################################
        ###          FERRAMENTA INTERATIVA PARA APLICAR AMBOS OS MODELOS       ###
        ##########################################################################
        print("\n\n--- FERRAMENTA DE ANÁLISE DE JOGADORES ---")

        def analisar_perfil_jogador(stats_jogador, modelos, scaler, feature_names):
            print(f"\n==================================================")
            print(f"--- Análise do Perfil do Jogador ---")
            print(f"Stats: {stats_jogador}")
            print(f"==================================================")
            
            try:
                # Prepara os dados uma única vez
                df_jogador = pd.DataFrame([stats_jogador], columns=feature_names)
                stats_normalizadas = scaler.transform(df_jogador)

                # Loop para aplicar cada modelo
                for nome_modelo, modelo in modelos.items():
                    previsao = modelo.predict(stats_normalizadas)
                    probabilidade = modelo.predict_proba(stats_normalizadas)
                    
                    classe_elite_index = np.where(modelo.classes_ == 'Elite')[0][0]
                    prob_elite = probabilidade[0][classe_elite_index]
                    
                    print(f"\nOpinião do Modelo: {nome_modelo}")
                    print("-" * 35)
                    print(f"  Previsão do Tier: {previsao[0]}")
                    print(f"  Confiança (Prob. de ser 'Elite'): {prob_elite:.2%}")

            except Exception as e:
                print(f"Erro ao analisar jogador: {e}")

        # Exemplos de Uso
        jogador_bom = {'Rounds': 150, 'KD': 1.15, 'ADR': 145, 'KPR': 0.82, 'APR': 0.3, 'FKPR': 0.11, 'FDPR': 0.11, 'HS%': 24, 'KAST': 76}
        jogador_monstro = {'Rounds': 150, 'KD': 1.4, 'ADR': 175, 'KPR': 0.98, 'APR': 0.2, 'FKPR': 0.16, 'FDPR': 0.09, 'HS%': 28, 'KAST': 79}
        
        analisar_perfil_jogador(jogador_bom, modelos_finais, scaler, X.columns)
        analisar_perfil_jogador(jogador_monstro, modelos_finais, scaler, X.columns)

    except Exception as e:
        print(f"\nO ERRO ORIGINAL FOI: {e}")
        print(f"Ocorreu um erro inesperado durante a execução do pipeline de Machine Learning.")
